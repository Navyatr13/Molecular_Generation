model:
  input_size: 35          # Corresponds to the size of CHARSET
  hidden_size: 501
  latent_size: 292
  num_layers: 3
  gru_output_size: 501

training:
  batch_size: 250
  epochs: 100
  learning_rate: 0.001
  optimizer: "adam"

data:
  dataset_path: './data/250k.npz'
  save_model_path: './save/vae_model.pth'
  charset: [' ', '#', '(', ')', '+', '-', '/', '1', '2', '3', '4', '5', '6', '7',
           '8', '=', '@', 'B', 'C', 'F', 'H', 'I', 'N', 'O', 'P', 'S', '[', '\\', ']',
           'c', 'l', 'n', 'o', 'r', 's']
  pad_length: 120
